# LAMP Explainer

Machine Learning models are now widely used in solving problems in a number of fields. While these models are powerful, it could be challenging to plug them in to an existing system that works well on itself. The main pain point with using predictive machine learning models in businesses is the explainability of th emodels predictions. The models just output a prediction for a given instance, this could raise questions as to why the model predicted what it did. The models do not inspire trust in the stakeholders if these questions are not answered. Explainablity of models is an emerging field that is a study to make models more understandable by getting insights about their predictions and their learning. 

The most famous explainability too is the SHAP values. Another powerful method to explain a models predictions is LIME. In this project we create a system that combines these two methods to explain the output of models. 
